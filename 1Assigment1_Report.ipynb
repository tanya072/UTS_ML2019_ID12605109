{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "1Assigment1_Report.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanya072/UTS_ML2019_ID12605109/blob/master/1Assigment1_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGUbBKkyGIRr",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCOuRmsaGIRu",
        "colab_type": "text"
      },
      "source": [
        "1. First impression\n",
        "    * What is my chosen paper to read?\n",
        "    * What type of the main contribution the paper has made?\n",
        "        - A theory or proposition (revealing something, from unknown to known)\n",
        "        - A method or algorithm (inventing a technique, from undoable to doable)\n",
        "\n",
        "    * _Before_ reading the main body of the paper, write down your first impression  obtained from its abstract and short introduction.\n",
        "    * Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "    \n",
        "2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list,  compare the list with people around you who have chosen the same or a similar paper.\n",
        "\n",
        "3. (During the next 7 days) Re-consider the central problem of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUKXUVJd9J07",
        "colab_type": "text"
      },
      "source": [
        "It is argued that the role of machine learning and neural networks as one of its techniques is crucial when it comes to image processing and pattern recognition.\n",
        "\n",
        "The underlying idea of the article: \"\"better pattern recognition systems can be built by relying more on automatic learning and less on hand designed heuristics. Using character recognition as a case study we show that hand crafted feature extraction can be advantageously replaced by carefully designed learning machines that operate directly on pixel images.\"\"(to paraphrase)\n",
        "\n",
        "The article is a comprehensive overview of Graph Transformer Networks, machine learning algorithm that uses Gradient-Based methods for online handwriting recognition and based on Convolutional Neural Network character recognisers as one of the deep learning techniques. Graph Transformer Network is designed to address the real-life application such as reading bank check and is deployed commercially with capacity to read a several million checks per day.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBBDF7PwGIRv",
        "colab_type": "text"
      },
      "source": [
        "[# Review Report](https://github.com/tanya072/Analytics-Capstone/blob/master/Copy_of_Copy_of_Copy_of_Copy_of_Copy_of_Copy_of_Copy_of_A1_ReportDraft.ipynb) \n",
        "on \"Gradient-Based Learning Applied to Document Recognition\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk9EQEMMGIRw",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX1BuK0KDmzC",
        "colab_type": "text"
      },
      "source": [
        "In the article \"Gradient-Based Learning Applied to Document Recognition\" Le Cun et al. (1998) claim that the role of machine learning and neural networks as one of its techniques is crucial when it comes to image processing and pattern recognition. However, until relatively recently, most pattern recognition models were relying heavily on hand-crafted algorithms more than on automatic learning. Hand-crafted algorithm is a feature extractor that locates characteristic regions or features of an image that is designed beforehand by human experts to extract a certain set of features, where they are then represented by low-dimensional vectors and can be distinguished and compared with others. Even though the feature-transformation algorithms are robust to scale variation and object rotation, this robustness comes at a high computational cost. The other issue related to feature extraction is that accuracy of the model is highly depended on what set of features the designers come up with and how these features are relevant to the images in given dataset. Furthermore, the set of features must be redone every time when a new problem arises.\n",
        "\n",
        "With emerging of new powerful machine-learning techniques, availability of low-cost machines and large datasets in early 1990s, the need for new feature extraction methods triggered an idea of developing deep learning algorithms that would obtain a set of features learned directly from observation of the input images. The research described by Le Cun et al. (1998) demonstrates great dedication to this idea and focuses on designing a new learning paradigm  that would reduce the need of the hand-crafted feature extractors, manual labelling and manual parameter tuning in document recognition systems. \n",
        "\n",
        "Le Cun et al. (1998) present a comprehensive overview of Graph Transformer Networks, machine learning algorithm that uses Gradient-Based learning method to minimise a loss function for  a given set of training data samples and their corresponding targets in  handwriting recognition, and is based on Convolutional Neural Network character recognisers as one of the deep learning techniques. Graph Transformer Network is designed to address the real-life application such as reading bank check and is deployed commercially with capacity to read a several million checks per day.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3r4Nr-QGIRx",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWJaJcgnGIRy",
        "colab_type": "text"
      },
      "source": [
        "The research comprises of a few sections where they are dedicated to following topics and discussions such as considering the task of handwritten character recognition, introduction of convolutional neural network such as LeNet-5 model and its architecture, comparing different learning techniques on a benchmark, introduction the concept of trainable Graph Transformer Network (GTN), describing discriminative and non-discriminative gradient-based techniques for training recogniser without manual segmentation and labelling, introduction of Space Displacement Neural Network without the need for segmentation heuristic, implementation of GTN in online handwriting recognition based on Convolutional Neural Network (CNN),  and finally, description of commercial GTN-based model for reading handwritten and printed bank checks. \n",
        "\n",
        "LeCun et al. (1998) explicitly divides handwriting recognition task on two conceptually different approaches: one is based on isolated or single character recognition, known as segmentation, and have been intensively studied in the literature by Srihari (1992) and other authors; the other one is to read the characters at the word level without manual segmentation and labelling. The reason for emerging handwriting recognition methods that would allow to train the recogniser at the word level rather than training pre-segmented characters, was difficulties that were related to separation out the characters from their neighbours in the sentence or the line of characters. The classic solution of this problem is called Heuristic Over-Segmentation (HOS). The technique is designed so that it generates a large number of potential cuts between characters using image processing techniques and selects the best combination of cuts based on scores assigned to each candidate character by recogniser. The main advantage of HOS is that it takes less time to make a decision about the segmentation due to a large number of possible variations of cuts. However, the accuracy of the method depends on the quality of cuts generated by segmenter and the ability of the recogniser to distinguish correctly segmented characters from pieces of characters, multiple or incorrectly segmented characters. This task presents the major challenge because the labelling database of incorrectly segmented characters can only be performed manually. It is tedious, costly and difficult to perform labelling uniformly due to great variations in naturally written sequences of characters.\n",
        "\n",
        "To address the issue related to segmentation, two solution are represented by LeCun et al. (1998). First one is based on training the model at the level of whole word rather than the character and introduces the idea of GTN. GTN is a generalisation of multilayer network where the information is represented as graphs instead of fixed-sized vectors. The second solution is designed to reject the segmentation altogether. Both solutions are using Gradient-Based Learning methods to minimise an overall loss function and include CNN LeNet-5 as a recogniser. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_VBB0U3GIRz",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRuHhiUkGIR0",
        "colab_type": "text"
      },
      "source": [
        "Back to late 90s the pattern recognition systems comprised of multiple modules that included field locator, segmenter, recogniser and post-processor. Normally, each module was trained and optimised separately. To maximise the overall performance the system should have been assembled and manually adjusted with respective to a subset of all parameters. Innovative approach illustrated in this paper is to train the recognition system globally finding the global minimum of loss function that would satisfy all parameters in the system using Gradient-Based Learning. \n",
        "Three networks for handwritten recognition are proposed by this research:\n",
        "\n",
        "   a)\thandwriting recognition Graph Transformer Network (GTN) based on heuristic over-segmentation (HOS) where segmentation transformer performs the segmentation on the word level followed by LeNet-5 recogniser which recognises each segment and outputs a recognition graph, followed by a couple other transformers that finally extract the best interpretation from the recognition graph.\n",
        "  \n",
        "   b)\thandwriting recognition GTN based on Space Displacement Neural Network (SDNN) which first module is SDNN transformer and replaces convolutional recogniser. Its main function is to scan every possible location of the input image and spot every well-centered character. \n",
        "    \n",
        "   c)\tGTN Check Reading system comprises of field locator and segmenter followed by recognition transformer LeNet-5 that classifies, and finally a couple transformers that select the path with lowest penalty that corresponds to the best interpretation. \n",
        "    \n",
        "All modules in the system output graphs whose arcs carry numerical information about transformations occurred in the given module. Some parameters of the systems can be adjusted manually, however the weights of neural net recogniser must be learned. GTN learning algorithms utilise the gradient based minimisation methods as a general principle of learning techniques in complex dynamic architectures. They use GTN as one of the modules in order to reduce the need for hand-crafted heuristic, manual labelling and parameter adjustment.  \n",
        "\n",
        "The systems include CNN LeNet-5, the high-level convolutional network, as a character recogniser which plays the role of automated feature extractor and pretrained on database of pre-segmented and labelled characters MNIST dataset that was modified from NIST’s database. MNIST dataset contains 60,000 training and 10,000 test images of 28x28 pixels written characters. LeNet-5 was trained 20 epochs through, with different number of training samples: 15,000, 30,000 and 60,000. Results explicitly show that increased number of samples improve the accuracy of classification. To extend the size of original dataset, the researches apply augmentation technique to the dataset to artificially generate more samples up to 540000 with randomly selected parameters such as horizontal and vertical translations, scaling, squeezing, shearing. As result of data augmenation, the test error improved from 0.95% on original data to 0.8% on distorted data. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuxuQ2IDGIR1",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hery5SDyGIR2",
        "colab_type": "text"
      },
      "source": [
        "The technical development of the research is high quality. The authors apply Gradient-Based Learning methods to integrate graph-based statistical models such as GTN with Convolutional Neural Networks (CNN). There are a few performance evaluations based on error rates of performed tests. Firstly, the researchers discuss about different classification models and how they perform on test data with and without applying artificially distorted training data in some cases. All models are trained on MNIST dataset with 60,000 training samples. The methods show various results ranging from 12% error rate for Linear model and 0.7% error rate for Boosted LeNet-4 (LeCun 1998, p.12). Even though, there is no need to do data augmentation due to the large size of the dataset, enlarging the initial dataset improved the accuracy of every model that it was applied to, and is a good example of experimentation practice.\n",
        "\n",
        "Secondly, comparing HOS and SDNN during on-line handwriting recognition experiment are based on sets of different parameters and supposed to measure improvements obtained from global training of the neural network with error rates of the training performed on the character-level. The effectiveness of these tests is arguable because they have quite different parameters, for instance, first set contains 100,000 hand printed characters which are extended in number with distorted data and are four type of characters: lower and upper case, digits and punctuation. The second and third sets are performed for recognition of 881 words. In the figure that illustrates the results and compare two methods, it is not clear what bars on the chart represent and where these results were extracted from. There is not enough explanation in the text either. \n",
        "\n",
        "All the test and experiments described in the study can be easily replicated due to open access to databases and specifications of classification algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAE1GgUNGIR3",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pOCBlYGGIR4",
        "colab_type": "text"
      },
      "source": [
        "The application domain of the proposed method is handwriting character recognition where the core of systems is Convolutional Neural Network LeNet-5 which uses back-propagation to learn the convolution filter coefficients directly from images of handwritten symbols. The success of this application is demonstrated throughout the set of experiment described by LeCun et al. (1998). The number of other domains in pattern and speech recognition where these systems or their modules can be applied grows constantly and have been described in numerous studies and researches. There are a few of them among other handwriting recognition, machine-printed character recognition, speech recognition, signature verification (Bromley et al. 1993) and face recognition (Lawrence et al. 1997) that utilise the idea of fixed-sized CNN. Bromley et al. (1993) neural network algorithm is not only resistant to forgeries but also robust to scale variations of signature and general direction of signing. Combination of neural networks and Hidden Markov Model is famously known for speech-recognition systems developed in late 80s. Implications of SDNN/HMM hybrid are found in design of speech-recognition system, face location (Vaillant et al. 1994), address block location on envelopes, hand-tracking in video. \n",
        "\n",
        "Further developments in successful implementation and improved performance of CNN models in pattern recognition might follow next avenues: selection of the CNN with better architecture to improve generalisation, dataset augmentation ensuring the large number of training samples, transfer learning and fine tuning applied to neural models to avoid overfitting, careful selection and determination of parameters for the model (number of epochs, dropout rate, learning rate and optimizer). An ensemble of a few recognisers can be used to improve accuracy of the model such as in case with CNN Boosted LeNet-4 mentioned in the study where three convolutional networks combined. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RumR0SuNGIR5",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g747TCkOGIR5",
        "colab_type": "text"
      },
      "source": [
        "The overall structure of paper is clear in some sections and slightly confusing in others. It would be more attractive if authors organise the sections that were united under the same topic or idea. For instance, the discussion about Heuristic Over-Segmentation (HOS) method and Space Displacement Neural Network (SDNN) method is interrupted by other section and then returns to HOS and SDNN again in Section IX where these two methods are compared in on-line handwriting recognition experiments. It would be much easier to read the sections that convey information to each other smoothly.  It is not easy to follow the section where authors discuss models included Hidden Markov Model (HMM) due to not sufficient explanation and presentation of HMM in the study. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTafRFRYGIR6",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "\n",
        "\n",
        "Bromley, J., Bentz, J.W., Bottou, L., Guyon, I., LeCun, Y., Moore, C., Sackinger, E. & Shah, R. 1993, ‘Signature verification using a siamese time delay neural network’, *International Journal of Pattern Recognition and Artificial Intelligence*, vol. 7, no. 4, pp. 669-687.\n",
        "\n",
        "Hubel, D.H. & Wiesel, T.N. 1962, ‘Receptive fields, binocular interaction and functional architecture in the cat's visual cortex’, *J Physiol*, pp. 106–154.\n",
        "\n",
        "Lawrence, S., Lee Giles, C., Tsoi, A.C. & Back, A.D. 1997, ‘Face recognition: A convolutional neural network approach’, *IEEE Transactions on Neural Networks*, vol. 8, no. 1, pp. 98-113.\n",
        "\n",
        "LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W. & Jackel, L.D. 1989, ‘Backpropagation Applied to Handwritten Zip Code Recognition’, *Neural Computation*, vol. 1, pp. 541-551.\n",
        "\n",
        "LeCun, Y., Bottou, L., Bengio, Y. & Haffner, P. 1998, 'Gradient-Based Learning Applied to Document Recognition', *Proceedings of the IEEE*, vol. 86, no. 11, pp. 1-46.\n",
        "\n",
        "Srihari, S.N. 1992, ‘High performance reading machines’, *Proceedings of the IEEE, Special issue on Optical Character Recognition*, vol. 80, no. 7, pp. 1120-1132.\n",
        "\n",
        "Vaillant, R., Monrocq, C. & LeCun, Y. 1994, ‘Original approach for the localization of objects in images’, *IEE Proceedings: Vision, Image and Signal Processing*, vol. 141, no. 4, pp. 245-250.\n",
        "\n",
        "[1]:https://google.com"
      ]
    }
  ]
}