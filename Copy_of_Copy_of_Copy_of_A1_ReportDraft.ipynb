{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Copy of Copy of Copy of A1_ReportDraft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanya072/UTS_ML2019_ID12605109/blob/master/Copy_of_Copy_of_Copy_of_A1_ReportDraft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGUbBKkyGIRr",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCOuRmsaGIRu",
        "colab_type": "text"
      },
      "source": [
        "1. First impression\n",
        "    * What is my chosen paper to read?\n",
        "    * What type of the main contribution the paper has made?\n",
        "        - A theory or proposition (revealing something, from unknown to known)\n",
        "        - A method or algorithm (inventing a technique, from undoable to doable)\n",
        "\n",
        "    * _Before_ reading the main body of the paper, write down your first impression  obtained from its abstract and short introduction.\n",
        "    * Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "    \n",
        "2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list,  compare the list with people around you who have chosen the same or a similar paper.\n",
        "\n",
        "3. (During the next 7 days) Re-consider the central problem of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUKXUVJd9J07",
        "colab_type": "text"
      },
      "source": [
        "It is argued that the role of machine learning and neural networks as one of its techniques is crucial when it comes to image processing and pattern recognition.\n",
        "\n",
        "The underlying idea of the article: \"\"better pattern recognition systems can be built by relying more on automatic learning and less on hand designed heuristics. Using character recognition as a case study we show that hand crafted feature extraction can be advantageously replaced by carefully designed learning machines that operate directly on pixel images.\"\"(to paraphrase)\n",
        "\n",
        "The article is a comprehensive overview of Graph Transformer Networks, machine learning algorithm that uses Gradient-Based methods for online handwriting recognition and based on Convolutional Neural Network character recognisers as one of the deep learning techniques. Graph Transformer Network is designed to address the real-life application such as reading bank check and is deployed commercially with capacity to read a several million checks per day.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBBDF7PwGIRv",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Gradient-Based Learning Applied to Document Recognition\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk9EQEMMGIRw",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX1BuK0KDmzC",
        "colab_type": "text"
      },
      "source": [
        "In the article \"Gradient-Based Learning Applied to Document Recognition\" Le Cun et al. (1998) claim that the role of machine learning and neural networks as one of its techniques is crucial when it comes to image processing and pattern recognition. However, until relatively recently, most pattern recognition models were relying heavily on hand-crafted algorithms more than on automatic learning. Hand-crafted algorithm is a feature extractor that locates characteristic regions or features of an image that is designed beforehand by human experts to extract a certain set of features, where they are then represented by low-dimensional vectors and can be distinguished and compared with others. Even though the feature-transformation algorithms are robust to scale variation and object rotation, this robustness comes at a high computational cost. The other issue related to feature extraction is that accuracy of the model is highly depended on what set of features the designers come up with and how these features are relevant to the images in given dataset. Furthermore, the set of features must be redone every time when a new problem arises.\n",
        "\n",
        "With emerging of new powerful machine-learning techniques, availability of low-cost machines and large datasets in early 1990s, the need for new feature extraction methods triggered an idea of developing deep learning algorithms that would obtain a set of features learned directly from observation of the input images. The research described by Le Cun et al. (1998) demonstrates great dedication to this idea and focuses on designing a new learning paradigm  that would reduce the need of the hand-crafted feature extractors, manual labelling and manual parameter tuning in document recognition systems. \n",
        "\n",
        "Le Cun et al. (1998) present a comprehensive overview of Graph Transformer Networks, machine learning algorithm that uses Gradient-Based learning method to minimise a loss function for  a given set of training data samples and their corresponding targets in  handwriting recognition, and is based on Convolutional Neural Network character recognisers as one of the deep learning techniques. Graph Transformer Network is designed to address the real-life application such as reading bank check and is deployed commercially with capacity to read a several million checks per day.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3r4Nr-QGIRx",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWJaJcgnGIRy",
        "colab_type": "text"
      },
      "source": [
        "The research comprises of a few sections where they are dedicated to following topics and discussions such as considering the task of handwritten character recognition, introduction of convolutional neural network such as LeNet-5 model and its architecture, comparing different learning techniques on a benchmark, introduction the concept of trainable Graph Transformer Network (GTN), describing discriminative and non-discriminative gradient-based techniques for training recogniser without manual segmentation and labelling, introduction of Space Displacement Neural Network without the need for segmentation heuristic, implementation of GTN in online handwriting recognition based on Convolutional Neural Network (CNN),  and finally, description of commercial GTN-based model for reading handwritten and printed bank checks. \n",
        "\n",
        "LeCun et al. (1998) explicitly divides handwriting recognition task on two conceptually different approaches: one is based on isolated or single character recognition, known as segmentation, and have been intensively studied in the literature by Srihari (1992) and other authors; the other one is to read the characters at the word level without manual segmentation and labelling. The reason for emerging handwriting recognition methods that would allow to train the recogniser at the word level rather than training pre-segmented characters, was difficulties that related to separation out the characters from their neighbours in the sentence or the line of characters. The classic solution of this problem is called Heuristic Over-Segmentation (HOS). The technique is designed so that it generates a large number of potential cuts between characters using image processing techniques and selects the best combination of cuts based on scores assigned to each candidate character by recogniser. The main advantage of HOS is that it takes less time to make a decision about the segmentation due to a large number of possible variations of cuts. However, the accuracy of the method depends on the quality of cuts generated by segmenter and the ability of the recogniser to distinguish correctly segmented characters from pieces of characters, multiple or incorrectly segmented characters. This task presents the major challenge because the labelling database of incorrectly segmented characters can only be performed manually, is tedious, costly and difficult to perform labelling uniformly due to great variations in naturally written sequences of characters.\n",
        "\n",
        "To address the issue related to segmentation, two solution are represented by LeCun et al. (1998). First one is based on training the model at the level of whole word rather than the character and introduces the idea of GTN. The second solution is designed to reject the segmentation altogether. Both solutions are using Gradient-Based Learning methods to minimise an overall loss function. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_VBB0U3GIRz",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRuHhiUkGIR0",
        "colab_type": "text"
      },
      "source": [
        "The background at the time of the work is that people understood the problem as .... The creative idea is ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuxuQ2IDGIR1",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hery5SDyGIR2",
        "colab_type": "text"
      },
      "source": [
        "The technical development if of high/low quality. The authors supported their theory using ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAE1GgUNGIR3",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pOCBlYGGIR4",
        "colab_type": "text"
      },
      "source": [
        "I find the proposal in the paper promising. ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RumR0SuNGIR5",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g747TCkOGIR5",
        "colab_type": "text"
      },
      "source": [
        "The overall strucutre is clear. I found reading is easy / difficult. The paper could have been more attractive if the authors had organised ... / provided ... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTafRFRYGIR6",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "[SHA48][1]: Author, Title, Info\n",
        "\n",
        "[1]:https://google.com"
      ]
    }
  ]
}